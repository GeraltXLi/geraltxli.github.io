<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://geraltxli.github.io</id>
    <title>GeraltXLi</title>
    <updated>2021-06-03T15:12:34.692Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://geraltxli.github.io"/>
    <link rel="self" href="https://geraltxli.github.io/atom.xml"/>
    <subtitle>The flash that cuts through darkness, the light that breaks the night.</subtitle>
    <logo>https://geraltxli.github.io/images/avatar.png</logo>
    <icon>https://geraltxli.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, GeraltXLi</rights>
    <entry>
        <title type="html"><![CDATA[ClickHouse单机安装，高可用版部署和简单使用]]></title>
        <id>https://geraltxli.github.io/post/clickhouse-dan-ji-an-zhuang-he-gao-ke-yong-ban-bu-shu/</id>
        <link href="https://geraltxli.github.io/post/clickhouse-dan-ji-an-zhuang-he-gao-ke-yong-ban-bu-shu/">
        </link>
        <updated>2021-06-02T15:16:23.000Z</updated>
        <summary type="html"><![CDATA[<p>最近用于OLAP场景的列式数据库ClickHouse挺火的，这里简单讲一下安装，部署和使用。不过阿里云都有SaaS版直接使用了，没有的才要自己搭🤡</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近用于OLAP场景的列式数据库ClickHouse挺火的，这里简单讲一下安装，部署和使用。不过阿里云都有SaaS版直接使用了，没有的才要自己搭🤡</p>
<!-- more -->
<h1 id="单机版">单机版</h1>
<h2 id="1-安装部署">1. 安装部署</h2>
<p><a href="https://clickhouse.tech/docs/en/getting-started/tutorial/">官方文档</a></p>
<p>单机安装，怎么快怎么来，实际上就这些：</p>
<pre><code class="language-bash">sudo apt-get install apt-transport-https ca-certificates dirmngr
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E0C56BD4

echo &quot;deb https://repo.clickhouse.tech/deb/stable/ main/&quot; | sudo tee \
    /etc/apt/sources.list.d/clickhouse.list
sudo apt-get update

sudo apt-get install -y clickhouse-server clickhouse-client

sudo service clickhouse-server start
clickhouse-client
</code></pre>
<h2 id="2-启动命令">2. 启动命令</h2>
<p>如果找不到service的话，debian可以直接去这目录，另外也可以看看实际启动命令是啥，</p>
<p>启动：</p>
<pre><code class="language-bash">$debian /usr/sbin/service clickhouse-server start

# 启动配置见
vim /etc/systemd/system/clickhouse-server.service
</code></pre>
<h2 id="3-配置文件">3. 配置文件</h2>
<h3 id="存储配置">存储配置</h3>
<p>这里是参考官方文档抄的存储策略，直接写在<code>config.d</code>目录下的<code>storage.xml</code><br>
(默认SSD，触发条件时迁移hdd)</p>
<pre><code class="language-xml">&lt;yandex&gt;
    &lt;storage_configuration&gt;
        &lt;disks&gt;
            &lt;fast_ssd&gt;
                &lt;path&gt;/data/fast_ssd/&lt;/path&gt;
            &lt;/fast_ssd&gt;
            &lt;hdd1&gt;
                &lt;path&gt;/home/clickhouse/hdd1/&lt;/path&gt;
            &lt;/hdd1&gt;
        &lt;/disks&gt;
        &lt;policies&gt;
            &lt;moving_from_ssd_to_hdd&gt;
                &lt;volumes&gt;
                    &lt;hot&gt;
                        &lt;disk&gt;fast_ssd&lt;/disk&gt;
                        &lt;max_data_part_size_bytes&gt;1073741824&lt;/max_data_part_size_bytes&gt;
                    &lt;/hot&gt;
                    &lt;cold&gt;
                        &lt;disk&gt;hdd1&lt;/disk&gt;
                    &lt;/cold&gt;
                &lt;/volumes&gt;
                &lt;move_factor&gt;0.2&lt;/move_factor&gt;
            &lt;/moving_from_ssd_to_hdd&gt;
        &lt;/policies&gt;
    &lt;/storage_configuration&gt;
&lt;/yandex&gt;

</code></pre>
<h2 id="4-建表">4. 建表</h2>
<p>举个例子(实际使用必须确定清楚<strong>表引擎</strong>和<strong>聚合函数</strong>)，这里只是现场想个例子展示预聚合用法:</p>
<ul>
<li>表引擎使用: <code>MergeTree</code>，简单聚合函数</li>
<li>order by就是主键了</li>
<li>按时间分区</li>
<li>存储策略是优先SSD，上面那个</li>
<li>存储时间两个月</li>
</ul>
<pre><code class="language-sql">create table test.user_info
(
    record_time DateTime('Asia/Shanghai'),
    user String,
    cost Float64
)ENGINE = MergeTree()
ORDER BY (record_time,user)
PARTITION BY record_time
SETTINGS storage_policy = 'moving_from_ssd_to_hdd'
TTL record_time + INTERVAL 2 MONTH

-- 创建物化视图，比如每天每个用户cost总量
CREATE MATERIALIZED VIEW user_info_daily_mv
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(day)
SETTINGS storage_policy = 'moving_from_ssd_to_hdd'
ORDER BY (day,user)
AS SELECT
    toStartOfDay(record_time) AS day,
    user ,
    sum(cost) as cost_count
FROM test.user_info
GROUP BY (day,user)
</code></pre>
<h1 id="集群版带副本">集群版（带副本）</h1>
<h2 id="1-zookeeper集群部署">1. zookeeper集群部署</h2>
<blockquote>
<p>正式环境貌似要设置zookeeper的日志清理</p>
</blockquote>
<h3 id="测试用compose直接起">测试用compose直接起</h3>
<pre><code>version: '3.1'

services:
  zoo1:
    image: zookeeper
    restart: always
    hostname: zoo1
    ports:
      - 2181:2181
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=0.0.0.0:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181

  zoo2:
    image: zookeeper
    restart: always
    hostname: zoo2
    ports:
      - 2182:2181
    environment:
      ZOO_MY_ID: 2
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=0.0.0.0:2888:3888;2181 server.3=zoo3:2888:3888;2181

  zoo3:
    image: zookeeper
    restart: always
    hostname: zoo3
    ports:
      - 2183:2181
    environment:
      ZOO_MY_ID: 3
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=0.0.0.0:2888:3888;2181
</code></pre>
<h3 id="手动安装">手动安装</h3>
<p>这部分删了，手动装挺麻烦的，这部分不大确定，虽然是能跑起来</p>
<h2 id="2-安装clickhouse">2. 安装clickhouse</h2>
<p>同上</p>
<h2 id="3-更新配置2分片2副本">3. 更新配置(2分片2副本)</h2>
<blockquote>
<p>不建议一个clickhouse-server拥有两个replicas来自不同shard。（除了性能问题，还会存在分布式DDL无法使用）<br>
见<a href="https://altinity.com/blog/2018/5/10/circular-replication-cluster-topology-in-clickhouse">CIRCULAR REPLICATION CLUSTER TOPOLOGY IN CLICKHOUSE</a>中的设计和<a href="https://github.com/ClickHouse/ClickHouse/issues/7611">github上issue所提的问题</a></p>
</blockquote>
<p>即每台机器是代表某个分片的某个副本</p>
<h3 id="所有配置文件">所有配置文件</h3>
<ul>
<li>config.xml (主配置文件)</li>
<li>users.xml (用户及配置限制)</li>
<li>storeage.xml (存储与策略配置)</li>
<li>metrika.xml（集群配置）</li>
</ul>
<h3 id="configxml-主配置文件">config.xml (主配置文件)</h3>
<pre><code>&lt;listen_host&gt;0.0.0.0&lt;/listen_host&gt;
</code></pre>
<h3 id="storagexml-存储与策略配置">storage.xml (存储与策略配置)</h3>
<p>见单机版，冷热数据划分，实际规则</p>
<ul>
<li>part超过1G的迁移</li>
<li>ssd快不够容量时迁移</li>
</ul>
<h3 id="userxml用户配置">user.xml(用户配置）</h3>
<ul>
<li>配置文件见<a href="https://clickhouse.tech/docs/en/operations/settings/settings-users/">user settings</a></li>
<li>可以设置个默认密码，用户账号管理用<a href="https://clickhouse.tech/docs/en/operations/access-rights/#access-control">SQL-driven workflow</a></li>
</ul>
<h3 id="metrikaxml文件cluster配置">metrika.xml文件（cluster配置）</h3>
<ul>
<li>申请4台机器，两个分片，2个副本</li>
<li>1和2的机器在同一个分片下，3和4在同一个分片下</li>
</ul>
<pre><code class="language-xml">&lt;yandex&gt;
    &lt;remote_servers&gt;
        &lt;test_cluster&gt;
            &lt;shard&gt;
                &lt;!-- &lt;secret&gt;&lt;/secret&gt; --&gt;
                &lt;!-- Optional. Shard weight when writing data. Default: 1. --&gt;
                &lt;weight&gt;1&lt;/weight&gt;
                &lt;!-- Optional. Whether to write data to just one of the replicas. Default: false (write data to all replicas). --&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt;
                    &lt;!-- Optional. Priority of the replica for load balancing (see also load_balancing setting). Default: 1 (less value has more priority). --&gt;
                    &lt;!-- &lt;priority&gt;1&lt;/priority&gt; --&gt;
                    &lt;host&gt;xx.xxx.xx.xx1&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;replica&gt;
                    &lt;host&gt;xx.xxx.xx.xx2&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
            &lt;shard&gt;
                &lt;weight&gt;1&lt;/weight&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt;
                    &lt;host&gt;xx.xxx.xx.xx3&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;replica&gt;
                    &lt;host&gt;xx.xxx.xx.xx4&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
        &lt;/test_cluster&gt;
    &lt;/remote_servers&gt;

    &lt;!-- 这里其实就是标记当前机器属于哪个shard，以及副本代号 --&gt;
    &lt;macros&gt;
        &lt;shard&gt;01&lt;/shard&gt;
        &lt;replica&gt;xx.xxx.xx.xx1&lt;replica&gt;
    &lt;/macros&gt;

    &lt;!-- ZK--&gt;
    &lt;zookeeper&gt;
        &lt;node index=&quot;1&quot;&gt;
            &lt;host&gt;xx.xxx.xx.xx1&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;2&quot;&gt;
            &lt;host&gt;xx.xxx.xx.xx2&lt;/host&gt;
            &lt;port&gt;2182&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;3&quot;&gt;
            &lt;host&gt;xx.xxx.xx.xx3&lt;/host&gt;
            &lt;port&gt;2183&lt;/port&gt;
        &lt;/node&gt;
    &lt;/zookeeper&gt;
    
&lt;/yandex&gt;
</code></pre>
<h3 id="宏定义统一建表语句">宏定义(统一建表语句)</h3>
<p>这里不设置layer层了，没必要</p>
<h4 id="记得每个节点都必须更新这个"><strong>记得每个节点都必须更新这个！！！</strong></h4>
<h4 id="注意同一个shard的节点的shard配置必须一致"><strong>注意同一个shard的节点的shard配置必须一致！！</strong></h4>
<pre><code class="language-xml">&lt;macros&gt;
    &lt;shard&gt;01&lt;/shard&gt;
    &lt;replica&gt;hostname&lt;/replica&gt;
&lt;/macros&gt;
</code></pre>
<h4 id="建表如果带上shard或者replica不能使用分布式ddl">建表如果带上{shard}或者{replica}，不能使用分布式DDL</h4>
<p>具体见<a href="https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/replication/">官方文档replication描述</a></p>
<blockquote>
<p>The replica name identifies different replicas of the same table. You can use the server name for this, as in the example. The name only needs to be unique within each shard.<br>
You can define the parameters explicitly instead of using substitutions. This might be convenient for testing and for configuring small clusters. However, you can’t use distributed DDL queries (ON CLUSTER) in this case.</p>
</blockquote>
<h3 id="最终配置文件">最终配置文件</h3>
<h4 id="丢到configd目录下覆盖默认配置">丢到config.d目录下覆盖默认配置</h4>
<ul>
<li>xxx.xml（合并了listen配置和storeage配置）</li>
<li>metrika.xml（单独，这部分是热更新，无需重启）</li>
</ul>
<h4 id="用户配置丢到userd目录下覆盖默认配置">用户配置丢到user.d目录下覆盖默认配置</h4>
<ul>
<li>users.xml</li>
</ul>
<h3 id="集群样例">集群样例</h3>
<p>具体可以去查看system的cluster表，看看集群配置是否生效了</p>
<h2 id="4-每个节点启动click-server确定互通">4. 每个节点启动click server(确定互通)</h2>
<ul>
<li>9000端口用于clickhouse互通与clickhouse-client</li>
<li>8123端口为http访问</li>
</ul>
<h2 id="5-建表">5. 建表</h2>
<pre><code class="language-sql">/*分布式DDL建库*/
CREATE DATABASE test ON CLUSTER 'test_cluster'

/*每台机器跑一次建表，但通过宏定义可以保证每个库建表语句一致*/
CREATE TABLE test.test_info_local (
    ......
)ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/test/test_info_local','{replica}')
PARTITION BY record_time
ORDER BY (record_time)
TTL record_time + INTERVAL 6 MONTH
SETTINGS storage_policy = 'moving_from_ssd_to_hdd'

/*分布式DDL建立原始数据分布表*/
CREATE TABLE  test.test_info_local on CLUSTER 'test_cluster'
as test.test_info
ENGINE = Distributed(test_cluster,test,test_info_local,rand())

/*以下不写了，基本看官方文档详细点*/
/*物化视图有实际table的，只不过默认隐藏，我们也可以手动创建*/


/*分布式DDL创建物化视图*/
/*这里因为提前建好复制表了，不需要再设置engine那些*/



/**分布式DDL 创建全局视图*/

</code></pre>
<ul>
<li>每个实例跑一次建表</li>
<li>分布式DDL跑一次就够了</li>
</ul>
<h2 id="6-实际应用">6. 实际应用</h2>
<h3 id="写本地表">写本地表</h3>
<p>最好直接写本地表，因为直接写分布式表，在clickhouse上还要再同步一次，实际上相当于双写了</p>
<h3 id="读分布式表">读分布式表</h3>
<h2 id="7-测试">7. 测试</h2>
<p>性能方面简单的可以看<a href="https://clickhouse.tech/docs/en/introduction/performance/">官方说明</a>，尽量批量写，这里其实还会涉及到clickhouse里part的概念，不细说了</p>
<blockquote>
<p>We recommend inserting data in packets of at least 1000 rows, or no more than a single request per second.</p>
</blockquote>
<h2 id="8-个人经验">8. 个人经验</h2>
<ul>
<li>表引擎要留意清楚，个人一般使用最多的是<code>SummingMergeTree</code>或者<code>AggregatingMergeTree</code>，分布式就加个<code>replica</code>前缀</li>
<li>clickhouse允许相同主键的数据存在，是否去重以及去重的规则具体看表引擎决定。</li>
<li>clickhouse不保证part merge的时机，这个是坑，某些实际应用场景时就会感受到的</li>
<li>可以对视图再进行视图的聚合，不过要注意，本质上是insert事件触发了视图，视图并不知道原表的数据</li>
</ul>
<p>有问题欢迎留言~</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gridea扩展(一)- 代码高亮]]></title>
        <id>https://geraltxli.github.io/post/gridea-kuo-zhan/</id>
        <link href="https://geraltxli.github.io/post/gridea-kuo-zhan/">
        </link>
        <updated>2021-05-30T14:27:40.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>没想到Gridea默认没有代码高亮，那只能自己来了，使用<strong>highlightjs</strong>，修改一下主题里代码，   引入一下就好了。</p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<p>没想到Gridea默认没有代码高亮，那只能自己来了，使用<strong>highlightjs</strong>，修改一下主题里代码，   引入一下就好了。</p>
</blockquote>
<!-- more -->
<h2 id="代码高亮">代码高亮</h2>
<ol>
<li>下载<a href="https://highlightjs.org/">highlight.js</a>，点<code>Get Version</code>去下载进行，里面也不少各种语言等之类的选择，一般默认就够用了</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://geraltxli.github.io/post-images/1622428479016.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>
<p>下载完后解压，简单点就把整个文件夹<code>highlight</code>都丢到gridea数据目录的<code>static</code>目录下（不过其实也可以直接copy里面的<code>highlight.pack.js</code>和<code>styles</code>目录）</p>
</li>
<li>
<p>去<code>themes</code>目录下修改，一般只有文章会用到，所以直接修改<code>post.ejs</code>。在head里加几行代码就行了，这里我选了<code>github-dark</code>样式，这个看自己爱好</p>
</li>
</ol>
<pre><code class="language-html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;&lt;%= themeConfig.domain %&gt;/highlight/styles/github-dark.css&quot;&gt;
    &lt;script src=&quot;&lt;%= themeConfig.domain %&gt;/highlight/highlight.pack.js&quot;&gt;&lt;/script&gt;
    &lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Golang-AES加密（CBC模式，PKCS7填充）]]></title>
        <id>https://geraltxli.github.io/post/golang-aes-jia-mi-cbc-mo-shi-pkcs7-tian-chong/</id>
        <link href="https://geraltxli.github.io/post/golang-aes-jia-mi-cbc-mo-shi-pkcs7-tian-chong/">
        </link>
        <updated>2021-05-30T13:33:56.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://github.com/FakerGit/go-tools/tree/master/encrypt">代码地址</a></p>
<blockquote>
<p>对称加密算法，即加密和解密使用一样的密钥的加解密算法。<br>
分组密码（block cipher），是每次只能处理特定长度的一块（block）数据的一类加解密算法。<br>
目前常见的对称加密算法DES、3DES、AES都是属于分组密码。</p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<p><a href="https://github.com/FakerGit/go-tools/tree/master/encrypt">代码地址</a></p>
<blockquote>
<p>对称加密算法，即加密和解密使用一样的密钥的加解密算法。<br>
分组密码（block cipher），是每次只能处理特定长度的一块（block）数据的一类加解密算法。<br>
目前常见的对称加密算法DES、3DES、AES都是属于分组密码。</p>
</blockquote>
<!-- more -->
<h3 id="背景">背景</h3>
<p>Golang没有像PHP那样提供一个现成的aes加密函数，不过标准库里有crypto，利用里面的aes等可以自己封装个加密函数，不过需要理解下整个加解密的过程和原理</p>
<!-- more -->
<hr>
<h3 id="aes加密详解">AES加密详解</h3>
<h4 id="1-参考文章golang-中aes加密详解">1. 参考文章<a href="https://blog.csdn.net/xiaohu50/article/details/51682849">golang 中AES加密详解</a></h4>
<h4 id="2-这里使用的是aes加密中的cbc模式块加密需要划分成整数长度相等个消息块不断加密串行分组长度是固定128位但密钥的长度可以使用128位192位或者256位这里指的是bit即密钥162432长度对应aes-128-aes-192-aes-256">2. 这里使用的是AES加密中的CBC模式，块加密需要划分成整数长度相等个消息块不断加密（串行），分组长度是固定128位，但密钥的长度可以使用128位，192位或者256位（这里指的是bit），即密钥16，24，32长度对应AES-128, AES-192, AES-256。</h4>
<h4 id="3初始向量要求随机但不需要保密">3.初始向量要求随机，但不需要保密。</h4>
<hr>
<h3 id="代码">代码</h3>
<p>自己研究代码比较清晰，根据<a href="https://golang.org/src/crypto/cipher/example_test.go">golang标准库AES实例代码</a>，再参考网上的PKCS7填充，最后进行base64的编码（因为加密后有些字符不可见）。最后Encrypt和Dncrypt两个就是AES加解密（CBC模式，PKCS7填充）封装后的函数，密钥位数限定16,24,32（要注意的是密钥无论多少，blocksize都是固定16）</p>
<pre><code class="language-go">package encrypt

import (
   &quot;bytes&quot;
   &quot;crypto/aes&quot;
   &quot;io&quot;
   &quot;crypto/rand&quot;
   &quot;crypto/cipher&quot;
   &quot;encoding/base64&quot;
)

/*CBC加密 按照golang标准库的例子代码
不过里面没有填充的部分,所以补上
*/

//使用PKCS7进行填充，IOS也是7
func PKCS7Padding(ciphertext []byte, blockSize int) []byte {
   padding := blockSize - len(ciphertext) % blockSize
   padtext := bytes.Repeat([]byte{byte(padding)}, padding)
   return append(ciphertext, padtext...)
}

func PKCS7UnPadding(origData []byte) []byte {
   length := len(origData)
   unpadding := int(origData[length-1])
   return origData[:(length - unpadding)]
}

//aes加密，填充秘钥key的16位，24,32分别对应AES-128, AES-192, or AES-256.
func AesCBCEncrypt(rawData,key []byte) ([]byte, error) {
   block, err := aes.NewCipher(key)
   if err != nil {
   	panic(err)
   }

   //填充原文
   blockSize := block.BlockSize()
   rawData = PKCS7Padding(rawData, blockSize)
   //初始向量IV必须是唯一，但不需要保密
   cipherText := make([]byte,blockSize+len(rawData))
   //block大小 16
   iv := cipherText[:blockSize]
   if _, err := io.ReadFull(rand.Reader,iv); err != nil {
   	panic(err)
   }

   //block大小和初始向量大小一定要一致
   mode := cipher.NewCBCEncrypter(block,iv)
   mode.CryptBlocks(cipherText[blockSize:],rawData)

   return cipherText, nil
}

func AesCBCDncrypt(encryptData, key []byte) ([]byte,error) {
   block, err := aes.NewCipher(key)
   if err != nil {
   	panic(err)
   }

   blockSize := block.BlockSize()

   if len(encryptData) &lt; blockSize {
   	panic(&quot;ciphertext too short&quot;)
   }
   iv := encryptData[:blockSize]
   encryptData = encryptData[blockSize:]

   // CBC mode always works in whole blocks.
   if len(encryptData)%blockSize != 0 {
   	panic(&quot;ciphertext is not a multiple of the block size&quot;)
   }

   mode := cipher.NewCBCDecrypter(block, iv)

   // CryptBlocks can work in-place if the two arguments are the same.
   mode.CryptBlocks(encryptData, encryptData)
   //解填充
   encryptData = PKCS7UnPadding(encryptData)
   return encryptData,nil
}


func Encrypt(rawData,key []byte) (string,error) {
   data, err:= AesCBCEncrypt(rawData,key)
   if err != nil {
   	return &quot;&quot;,err
   }
   return base64.StdEncoding.EncodeToString(data),nil
}

func Dncrypt(rawData string,key []byte) (string,error) {
   data,err := base64.StdEncoding.DecodeString(rawData)
   if err != nil {
   	return &quot;&quot;,err
   }
   dnData,err := AesCBCDncrypt(data,key)
   if err != nil {
   	return &quot;&quot;,err
   }
   return string(dnData),nil
}
</code></pre>
<pre><code class="language-json">{
    &quot;json&quot;:&quot;123&quot;,
    &quot;hah&quot;:&quot;123&quot;
}
</code></pre>
<hr>
<p><a href="https://github.com/FakerGit/go-tools">github代码地址</a></p>
<hr>
<p>参考：</p>
<ol>
<li><a href="https://blog.csdn.net/xiaohu50/article/details/51682849">golang 中AES加密详解</a></li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一次完整的网络请求过程]]></title>
        <id>https://geraltxli.github.io/post/yi-ci-wan-zheng-de-wang-luo-qing-qiu-guo-cheng/</id>
        <link href="https://geraltxli.github.io/post/yi-ci-wan-zheng-de-wang-luo-qing-qiu-guo-cheng/">
        </link>
        <updated>2021-05-30T07:03:38.000Z</updated>
        <summary type="html"><![CDATA[<p>从浏览器访问某个网站时所发生的事情</p>
]]></summary>
        <content type="html"><![CDATA[<p>从浏览器访问某个网站时所发生的事情</p>
<!-- more -->
<!-- more -->
<h2 id="一-dns解析">一、 DNS解析</h2>
<ul>
<li>浏览器搜索自身缓存的DNS记录（所以才会有修改host后有时候没立刻生效的原因）</li>
<li>搜索系统的hosts文件</li>
<li>路由器也有DNS缓存</li>
<li>无则继续向ISP的DNS服务请求</li>
<li>无
<ul>
<li>非转发模式：则向根服务器请求，进行递归查询，即根DNS服务器返回定义域名服务器的IP，然后到顶级域名（如<code>.com</code>服务器查询）解析，如果无法解析就会继续提供此下一级dns服务器（如<code>qq.com</code>去解析），直到找到位置</li>
<li>转发模式：dns服务器自身请求转发给上一级</li>
</ul>
</li>
</ul>
<blockquote>
<p>从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。</p>
</blockquote>
<h2 id="二-tcpip-协议栈通信过程">二、TCP/IP 协议栈通信过程</h2>
<figure data-type="image" tabindex="1"><img src="https://geraltxli.github.io/post-images/1622358377997.png" alt="" loading="lazy"></figure>
<h3 id="1-应用层">1. 应用层</h3>
<p>定义数据格式，并按照格式解析数据。<br>
此时是HTTP协议，header的content-type定义格式，body填数据</p>
<h3 id="2-传输层">2. 传输层</h3>
<h4 id="协议栈上">协议栈上</h4>
<p>添加了TCP首部，记录端口，确认主机上应用程序的身份，把数据包交给对应的应用程序</p>
<h4 id="tcp三次握手和四次挥手">TCP三次握手和四次挥手</h4>
<figure data-type="image" tabindex="2"><img src="https://geraltxli.github.io/post-images/1622358358701.png" alt="" loading="lazy"></figure>
<blockquote>
<p>ESTABLISHED <code>əˈstabliSHt</code> 已建立成功的状态</p>
</blockquote>
<ul>
<li>为什么握手要三次？为了防止已经失效的连接请求报文段突然又传到服务端</li>
<li>为什么挥手要四次？当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端</li>
<li>为什么TIME_WAIT状态需要经过2MSL（max segment lifetime，即最大报文段生存时间，一般1分钟到4分钟)才能返回到CLOSE状态？四个报文都发送完毕，我们可以直接进入CLOSE状态了，
<ul>
<li>但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。</li>
<li>保证此次连接的重复数据段从网络中消失<br>
TCP分节可能由于路由器异常而“迷路”，在“迷路”期间，TCP发送端可能因确认超时而重发这个分节，“迷路”的分节在路由器恢复正常后也会被发送到最终的目的地，这个迟到的“迷路”分节到达时可能会引起问题。在关闭“前一个连接”之后，马上又建立起一个相同的IP和端口之间的“新连接”，这会导致“前一个连接”的迷路重复分组在“前一个连接”终止后到达，从而被“新连接”接收到了。<br>
为了避免以上情况，TCP/IP协议不允许处于TIME_WAIT状态的连接启动一个新的可用连接，因为TIME_WAIT状态持续2MSL，这就可以保证当成功建立一个新TCP连接的时候，来自旧连接重复分组已经在网络中消失。</li>
</ul>
</li>
</ul>
<h3 id="3-网络层">3. 网络层</h3>
<p>定义网络地址，区分网段，子网内MAC寻址，对不同子网的数据包进行路由</p>
<ul>
<li>IP协议通过子网掩码计算网络地址，判断两个主机是否属于同一个子网</li>
<li>ARP协议以太网广播给子网的所有主机，IP地址相同的话，主机会返回MAC地址，不同则丢弃。与此同时，ARP会缓存这个映射关系。此时寻址限制于同一个子网</li>
<li>路由协议，不同子网，通过本子网的网关进行路由</li>
<li></li>
</ul>
<h3 id="4-链路层">4. 链路层</h3>
<ul>
<li>对电信号进行分组并形成具有特定意义的数据帧，然后以广播的形式通过物理介质发送给接收方。以太网规定一组电信号就是一个数据包，一个数据包被称为一帧， 制定这个规则的协议就是以太网协议。</li>
<li>子网广播，主机通过MAC地址来决定是否处理数据</li>
</ul>
]]></content>
    </entry>
</feed>