<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://geraltxli.github.io</id>
    <title>GeraltXLi</title>
    <updated>2021-07-31T02:53:04.344Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://geraltxli.github.io"/>
    <link rel="self" href="https://geraltxli.github.io/atom.xml"/>
    <subtitle>The flash that cuts through darkness, the light that breaks the night.&lt;br&gt;&lt;br&gt;
    Total &lt;span id=&quot;busuanzi_value_site_uv&quot;&gt;&lt;/span&gt; visitors.
&lt;/span&gt;</subtitle>
    <logo>https://geraltxli.github.io/images/avatar.png</logo>
    <icon>https://geraltxli.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, GeraltXLi</rights>
    <entry>
        <title type="html"><![CDATA[Clickhouse 介绍]]></title>
        <id>https://geraltxli.github.io/post/clickhouse-xiang-jie/</id>
        <link href="https://geraltxli.github.io/post/clickhouse-xiang-jie/">
        </link>
        <updated>2021-07-08T15:02:50.000Z</updated>
        <summary type="html"><![CDATA[<p>概述OLAP场景与列式数据库特征，以及Clickhouse这数据库的各个特性（各个特性的组合实现了clickhouse的高性能）</p>
]]></summary>
        <content type="html"><![CDATA[<p>概述OLAP场景与列式数据库特征，以及Clickhouse这数据库的各个特性（各个特性的组合实现了clickhouse的高性能）</p>
<!-- more -->
<h1 id="clickhouse-详解">Clickhouse 详解</h1>
<h2 id="一-概述">一、概述</h2>
<blockquote>
<p>ClickHouse® is a column-oriented database management system (DBMS) for online analytical processing of queries (OLAP).</p>
</blockquote>
<p>根据官方文档说法，它是列式数据库，应用于OLAP场景。</p>
<h3 id="olap">OLAP</h3>
<p>OLAP(OnLine Analysis Processing ，联机分析处理 )，是数据仓库系统的主要应用，从多维度，多层次的角度，针对特定问题进行数据的汇总分析。</p>
<h4 id="特征">特征</h4>
<blockquote>
<p>OLAP场景的关键特征<a href="https://clickhouse.tech/docs/zh/#olapchang-jing-de-guan-jian-te-zheng">¶</a></p>
<ul>
<li>绝大多数是读请求</li>
<li>数据以相当大的批次(&gt; 1000行)更新，而不是单行更新;或者根本没有更新。</li>
<li>已添加到数据库的数据不能修改。</li>
<li>对于读取，从数据库中提取相当多的行，但只提取列的一小部分。</li>
<li>宽表，即每个表包含着大量的列</li>
<li>查询相对较少(通常每台服务器每秒查询数百次或更少)</li>
<li>对于简单查询，允许延迟大约50毫秒</li>
<li>列中的数据相对较小：数字和短字符串(例如，每个URL 60个字节)</li>
<li>处理单个查询时需要高吞吐量(每台服务器每秒可达数十亿行)</li>
<li>事务不是必须的</li>
<li>对数据一致性要求低</li>
<li>每个查询有一个大表。除了他以外，其他的都很小。</li>
<li>查询结果明显小于源数据。换句话说，数据经过过滤或聚合，因此结果适合于单个服务器的RAM中</li>
</ul>
</blockquote>
<h3 id="列式数据库">列式数据库</h3>
<p>传统关系数据库的数据一般在按行存储，即一行数据在物理存储上位置是连续的，而列式数据库则是按列存储。值得注意的是，这里列式或者行式只是指数据库的存储模型（storage model），并不影响上层的数据模型（data model)，列式存储的数据库可能是SQL数据库或者NOSQL数据库。</p>
<h4 id="特征与优点">特征与优点：</h4>
<ul>
<li>数据库按列存储</li>
<li>数据即是索引</li>
<li>只访问查询涉及的列 - 大量降低系统IO</li>
<li>每列可单独线程处理 - 通过并发提高查询速度</li>
<li>数据类型一致，数据特征相似 - 高效压缩</li>
</ul>
<h4 id="优点">优点：</h4>
<ul>
<li><strong>更快的IO</strong>：对指定列查询统计分析时，因为只涉及指定列，不像行式会查询到其他列数据，减少IO，并且一定程度上随机读取变成顺序读取</li>
<li><strong>更低的存储（成本更低）</strong>：同一列数据更好压缩（比如字典表压缩）</li>
<li><strong>更低的内存和CPU</strong>：查询涉及的数据量低时（无论是因为只读了相关列或者是列的压缩），占用计算内存更少。</li>
</ul>
<h4 id="缺点">缺点：</h4>
<ul>
<li><strong>组装消耗</strong>：select完成后需要组装各个列数据</li>
<li><strong>插入更新更麻烦</strong>：比如一次插入，需要对多列操作，比如不同列在不同page，需要进行多次IO（行式可能只需一次）</li>
</ul>
<hr>
<h4 id="clickhouse-features官方文档说法">Clickhouse Features（官方文档说法）</h4>
<ul>
<li>
<p><strong>列式存储</strong>：In a real column-oriented DBMS, no extra data is stored with the values.  即数据不会有额外数据（比如记录数据长度）</p>
</li>
<li>
<p><strong>数据压缩</strong>：除了高效通用压缩codec（编解码器）之外，clickhouse还对特定类型的数据提供专门的codec</p>
</li>
<li>
<p><strong>磁盘存储</strong>：因为数据在物理存储上就是按主键排序了的，可以以低延迟（不到几十毫秒）提取特定值或者范围数据。Clickhouse设计是用于常规硬盘，成本更低，但如果允许，SSD或者更多RAM可以进一步提高性能</p>
</li>
<li>
<p><strong>多核并行处理</strong>：Clickhouse实际应用是可以跑满CPU内存资源的。</p>
</li>
<li>
<p><strong>多服务器上的分布式查询</strong>：数据多分片存储，各分片也可以有多个副本</p>
</li>
<li>
<p><strong>SQL支持</strong>：大部分情况满足ANSI SQL标准</p>
</li>
<li>
<p><strong>向量计算引擎</strong>（可见参考描述）：</p>
<ul>
<li>SIMD即<strong>single instruction, multiple data&quot;（单指令流多数据流)</strong>，本质上是采用一个控制器来控制多个处理器，同时对一组数据中的每一条分别执行相同的操作，从而实现空间上的并行性的技术。</li>
<li>CPU通过SSE指令集实现SIMD</li>
<li>clickhouse充分应用SSE指令集：filter（批量处理128位）或者大小写转换（一次加载16个字段转换）</li>
</ul>
</li>
<li>
<p><strong>实时数据更新</strong>：支持主键表，为了快速执行基于主键的范围查询，Clickhouse会使用合并树对数据进行增量排序，数据可以实时不断添加。（不过要特别注意clickhouse对于各个数据part的合并，合并的时机不定，实际业务也要有意识控制part大小）</p>
</li>
<li>
<p><strong>主键索引</strong>：查询主键的特定值或者特定范围的延迟非常低（不到几十毫秒），顺序读写</p>
</li>
<li>
<p><strong>二级索引</strong>：与其他数据库不同，clickhouse的二级索引不指向特定行或者行范围。相反，它们让数据库提前知道某些数据部分中的所有行都不会匹配查询过滤条件并且根本不读取它们，因此它们被称为<a href="https://clickhouse.tech/docs/en/engines/table-engines/mergetree-family/mergetree/#table_engine-mergetree-data_skipping-indexes"> data skipping indexes.</a>。比如：记录这个data part的年龄最小值是30岁，那么查询30岁以下数据时，就直接跳过整个data part，加快查询。</p>
</li>
<li>
<p><strong>支持在线查询</strong>：简而言之，就是查询太快了，所以允许在线实时查询，不需要像其他OLAP场景下跑离线任务。</p>
</li>
<li>
<p><strong>支持近似值的计算</strong>：ClickHouse提供各种各样在允许牺牲数据精度的情况下对查询进行加速的方法：</p>
<ul>
<li>
<p>用于近似计算的各类聚合函数，如：distinct values, medians, quantiles</p>
</li>
<li>
<p>基于数据的部分样本进行近似查询。这时，仅会从磁盘检索少部分比例的数据。</p>
</li>
<li>
<p>不使用全部的聚合条件，通过随机选择有限个数据聚合条件进行聚合。这在数据聚合条件满足某些分布条件下，在提供相当准确的聚合结果的同时降低了计算资源的使用。</p>
</li>
</ul>
</li>
<li>
<p><strong>自适应的Join算法</strong></p>
</li>
<li>
<p><strong>数据复制和完整性支持</strong>：ClickHouse使用异步的多主复制技术。当数据被写入任何一个可用副本后，系统会在后台将数据分发给其他副本，以保证系统在不同副本上保持相同的数据。在大多数情况下ClickHouse能在故障后自动恢复，在一些少数的复杂情况下需要手动恢复。</p>
</li>
<li>
<p><strong>基于角色的访问控制</strong></p>
</li>
<li>
<p><strong>可视为缺点的feature</strong></p>
<ul>
<li>没有完整的事务支持。</li>
<li>缺少高频率，低延迟的修改或删除已存在数据的能力。仅能用于批量删除或修改数据，但这符合 <a href="https://gdpr-info.eu/">GDPR</a>。</li>
<li>稀疏索引使得ClickHouse不适合通过其键检索单行的点查询。</li>
</ul>
</li>
</ul>
<h2 id="二-性能">二、性能</h2>
<h4 id="描述">描述</h4>
<p>根据<a href="https://clickhouse.tech/docs/en/introduction/performance/">官方文档</a>说法</p>
<ul>
<li>单个查询的吞吐量，提取一个10字节的列，处理速度大概是1-2亿行每秒</li>
<li>普通短查询正常小于50ms</li>
</ul>
<p>另外值得注意的是</p>
<ul>
<li>写入性能最好是批量写入，每次不少于1000行或者一秒一次插入。</li>
<li>写入的数据每行为1Kb，那么写入的速度为50，000到200，000行每秒（我实际业务测试时，单机十四万行插入为2秒多）</li>
<li>并发查询不要超过100/s</li>
</ul>
<h4 id="为啥这么快">为啥这么快</h4>
<p>看列式数据库的特征和clickhouse本身feature就大概知道了，列式存储加上压缩，减少读取数据，更少的IO，相同查询占用更少内存（成本也更低）。同时支持并发处理，clickhouse本身对于压缩和数据向量并行处理又做了优化，能更好地利用CPU，多核并行处理。</p>
<h2 id="三-备注">三、备注</h2>
<p>以上基本就是自己扫一遍clickhouse官方文档的特性，理解一下列式数据库和clickhouse特性实际上大概做了什么事情。有啥问题欢迎指正~</p>
<h1 id="参考">参考</h1>
<ul>
<li><a href="https://clickhouse.tech/docs/en/">官方文档</a></li>
<li><a href="https://blog.csdn.net/nieson2012/article/details/79551337">什么是列式存储数据库</a></li>
<li><a href="https://www.jianshu.com/p/c36f4e142b8a">漫谈SIMD、SSE指令集与Clickhouse向量化执行</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[服务端开发规范（未完待续）]]></title>
        <id>https://geraltxli.github.io/post/fu-wu-duan-kai-fa-gui-fan-todo/</id>
        <link href="https://geraltxli.github.io/post/fu-wu-duan-kai-fa-gui-fan-todo/">
        </link>
        <updated>2021-07-08T14:53:09.000Z</updated>
        <summary type="html"><![CDATA[<p>服务端开发遵守的Git, CHANGELOG, Version规范。</p>
]]></summary>
        <content type="html"><![CDATA[<p>服务端开发遵守的Git, CHANGELOG, Version规范。</p>
<!-- more -->
<h2 id="开发规范">开发规范</h2>
<ul>
<li><a href="https://www.conventionalcommits.org/en/v1.0.0/">git commit规范</a></li>
<li><a href="https://keepachangelog.com/en/1.0.0/">changelog规范</a></li>
<li><a href="https://semver.org/lang/zh-CN/">版本规范</a></li>
<li><a href="https://github.com/golang-standards/project-layout">Go项目目录结构</a></li>
</ul>
<p>未完待续...</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微服务治理- 学习笔记（一）]]></title>
        <id>https://geraltxli.github.io/post/wei-fu-wu-zhi-li-fa-zhan-xue-xi/</id>
        <link href="https://geraltxli.github.io/post/wei-fu-wu-zhi-li-fa-zhan-xue-xi/">
        </link>
        <updated>2021-06-19T07:52:42.000Z</updated>
        <summary type="html"><![CDATA[<p>微服务是一种研发模式，不是开发里引入微服务框架即可，而是涉及整个开发周期。<br>
最近在看《微服务治理》，顺便做下笔记，毕竟好记性不如烂键盘？</p>
]]></summary>
        <content type="html"><![CDATA[<p>微服务是一种研发模式，不是开发里引入微服务框架即可，而是涉及整个开发周期。<br>
最近在看《微服务治理》，顺便做下笔记，毕竟好记性不如烂键盘？</p>
<!-- more -->
<h2 id="1-单体架构">1. 单体架构</h2>
<h3 id="架构分层与组件库">架构分层与组件库</h3>
<p>最初在网站或者系统较小的时候，一般都是把所有功能模块打包一在一个工程直接部署。在我学生时期的大作业，或者刚工作时碰到功能较为简单或者访问量较小的网站之类就是如此。</p>
<ul>
<li>设计模式使用<strong>MVC</strong></li>
<li>实际开发通过<strong>框架</strong>(Framework)完成规范的约束</li>
<li>将通用功能模块抽离成功独立的<strong>通用组件库</strong>，解放业务开发人员对底层的关注。不过工程与组件库之间的依赖和组件库之间的依赖会组件形成网状关系，然后版本迭代进一步提升复杂度</li>
</ul>
<h3 id="不足">不足</h3>
<p>不过随着时间的推移，代码的不断迭代，整个工程终究会不断变成一个庞大的怪兽（如果一直活着）</p>
<ul>
<li>单体应用庞大又复杂时，甚至开发人员都发生了变更，没有开发者对其有完全了解，这时候无论是修BUG还是功能迭代，都会变得十分谨慎，容易恶性循环，谁都不愿意优化或者改动过大，单纯堆砌直到重构</li>
<li>单体应用庞大影响启停速度，从而影响开发效率与线上变更</li>
<li>单体应用碰到资源冲突时难以扩展，比如不同模块可能是cpu密集型或者io密集型，或者内存型之类的，部署成本更高</li>
<li>最后就是尾大不掉，太大了，难以进行架构升级与技术优化</li>
</ul>
<hr>
<h2 id="2-soa">2. SOA</h2>
<p>形式是服务总线（ESB）</p>
<ul>
<li>传统中间件技术加通信协议</li>
<li>由老牌大厂主导，复杂，庞大</li>
<li>服务治理粗糙，人工比例大</li>
</ul>
<p>不过我毕业后在互联网行业倒基本没怎么碰到过这个。</p>
<hr>
<h2 id="3-分布式服务与治理">3. 分布式服务与治理</h2>
<h3 id="背景">背景</h3>
<ul>
<li>互联网（xx敏捷开发)，版本迭代非常快</li>
<li>无论是网站还是应用，各个功能模块访问不均衡</li>
</ul>
<p>随着发展规模壮大，按业务拆分服务</p>
<h3 id="服务框架">服务框架</h3>
<p>轻量化SOA架构</p>
<ul>
<li>引入服务注册发现机制与远程调用机制</li>
<li>服务负载均衡</li>
<li>限流，降级和熔断保护机制</li>
</ul>
<p>将服务管控与运维能力下沉到框架层面，让业务开发者专注开发</p>
<h3 id="分布式服务治理">分布式服务治理</h3>
<ul>
<li>服务度量
<ul>
<li>服务基础与管理信息</li>
<li>服务质量和服务能力（支持XXXqps）</li>
<li>服务依赖和服务调用统计</li>
<li>服务物理分布</li>
</ul>
</li>
<li>服务管控
<ul>
<li>服务部署上下线</li>
<li>服务路由管控</li>
<li>服务限流，降级和熔断保护措施</li>
<li>服务授权（访问授权管理）</li>
</ul>
</li>
</ul>
<hr>
<h2 id="4-微服务及治理">4. 微服务及治理</h2>
<blockquote>
<p>微服务是一种研发模式，不止技术</p>
</blockquote>
<h3 id="背景-2">背景</h3>
<ol>
<li>docker技术的出现，极大降级服务部署与运维成本</li>
<li>服务应用规模越来越大，服务粒度越来越小（比如单纯的缓存服务）</li>
</ol>
<h3 id="架构模式特点">架构模式特点</h3>
<ul>
<li><strong>高内聚，低耦合。</strong> 根据业务边界确定服务边界，符合领域驱动设计（DDD），专心完成一件不可再分割的完整业务操作功能，即为微服务</li>
<li><strong>资源独享</strong>：像数据库资源便是独享，确保松耦合。不过会导致数据冗余，事务一致性也很麻烦</li>
<li><strong>模式</strong>：
<ul>
<li><strong>基于SDK的同构</strong>，由框架提供微服务一系列管控能力</li>
<li><strong>ServiceMesh(SideCar)</strong>，可以异构，sidecar就相当于一个透明代理，处理微服务路由与管控事情。</li>
</ul>
</li>
<li><strong>问题</strong>：
<ul>
<li><strong>单点依赖</strong>：存在通用服务被大部分其他服务调用（比如来个鉴权服务跪了，所有依赖的相关服务涉及鉴权的业务都得）</li>
<li><strong>循环调用</strong>：A-&gt;B-&gt;C-&gt;A</li>
<li><strong>服务冗余</strong>： 存在微服务已不再使用</li>
</ul>
</li>
<li><strong>调用关系梳理</strong>：
<ul>
<li>静态代码调用链路分析</li>
<li>动态线上调用依赖关系分析</li>
</ul>
</li>
</ul>
<h3 id="研发治理">研发治理</h3>
<ul>
<li>
<p><strong>小团队，小工程</strong>：不同微服务做好隔离，每个服务都是独立工程，提高各个工程的构建与部署效率；不要一个大工程，一个目录一个模块，CI构建不同微服务。（对于笔者实际工作经验来说，在开发某个应用的时候的确会出现这样的设计，原因应该就是多个工程创建繁琐，同一工程方便引用代码）</p>
</li>
<li>
<p><strong>工程与代码质量治理</strong>：正常都是发生在业务快速迭代期间，功能迭代，时间紧和任务重。要不临时修改，要不严格按照规范执行。（如果没有强制约束，非常容易出现先用临时方案做出来，后续有空再重构！！！实际上只要没出问题，一般不会有空去重构的）</p>
</li>
<li>
<p><strong>接口契约治理</strong>： 以接口形式提供内部功能，服务提供方需要确保变更不影响接口逻辑，或者保证变更能同步到调用方</p>
</li>
<li>
<p><strong>测试治理</strong>：单元测试和冒烟测试需要Mock，但也有局限（工作量，无法模拟网络延时等）；集成测试对线上服务完备性依赖强</p>
</li>
<li>
<p><strong>运维治理</strong>：服务集群节点规模大，调用层级多且复杂。需要对线上有完备的链路追踪与监控，能及时发现节点健康问题，进行修复或者资源调度；智能化运维（像笔者工作中便做过服务端日志智能归类平台，收集服务端日志，过滤清洗，归类统计与报警，减少程序工作量。）</p>
</li>
<li>
<p><strong>管理治理</strong>：敏捷开发（毕竟微服务架构即是灵活快速）；Devops，运维自动化将部署运维监控与管理让渡给开发者。如书中图（微服务全生命周期管理）</p>
<figure data-type="image" tabindex="1"><img src="https://geraltxli.github.io/post-images/1624098421948.png" alt="" loading="lazy"></figure>
<p>以上单纯是看书学习时做的一点笔记，有问题欢迎指正。</p>
<h2 id="参考">参考</h2>
<ul>
<li>《微服务治理》（刚开始看这本书）</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ClickHouse单机安装，高可用集群部署和简单使用]]></title>
        <id>https://geraltxli.github.io/post/clickhouse-dan-ji-an-zhuang-he-gao-ke-yong-ban-bu-shu/</id>
        <link href="https://geraltxli.github.io/post/clickhouse-dan-ji-an-zhuang-he-gao-ke-yong-ban-bu-shu/">
        </link>
        <updated>2021-06-02T15:16:23.000Z</updated>
        <summary type="html"><![CDATA[<p>最近用于OLAP场景的列式数据库ClickHouse挺火的，这里简单讲一下安装，部署和使用。不过阿里云都有SaaS版直接使用了，没有的才要自己搭🤡</p>
]]></summary>
        <content type="html"><![CDATA[<p>最近用于OLAP场景的列式数据库ClickHouse挺火的，这里简单讲一下安装，部署和使用。不过阿里云都有SaaS版直接使用了，没有的才要自己搭🤡</p>
<!-- more -->
<h1 id="单机版">单机版</h1>
<h2 id="1-安装部署">1. 安装部署</h2>
<p><a href="https://clickhouse.tech/docs/en/getting-started/tutorial/">官方文档</a></p>
<p>单机安装，怎么快怎么来，实际上就这些：</p>
<pre><code class="language-bash">sudo apt-get install apt-transport-https ca-certificates dirmngr
sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv E0C56BD4

echo &quot;deb https://repo.clickhouse.tech/deb/stable/ main/&quot; | sudo tee \
    /etc/apt/sources.list.d/clickhouse.list
sudo apt-get update

sudo apt-get install -y clickhouse-server clickhouse-client

sudo service clickhouse-server start
clickhouse-client
</code></pre>
<h2 id="2-启动命令">2. 启动命令</h2>
<p>如果找不到service的话，debian可以直接去这目录，另外也可以看看实际启动命令是啥，</p>
<p>启动：</p>
<pre><code class="language-bash">$debian /usr/sbin/service clickhouse-server start

# 启动配置见
vim /etc/systemd/system/clickhouse-server.service
</code></pre>
<h2 id="3-配置文件">3. 配置文件</h2>
<h3 id="存储配置">存储配置</h3>
<p>这里是参考官方文档抄的存储策略，直接写在<code>config.d</code>目录下的<code>storage.xml</code><br>
(默认SSD，触发条件时迁移hdd)</p>
<pre><code class="language-xml">&lt;yandex&gt;
    &lt;storage_configuration&gt;
        &lt;disks&gt;
            &lt;fast_ssd&gt;
                &lt;path&gt;/data/fast_ssd/&lt;/path&gt;
            &lt;/fast_ssd&gt;
            &lt;hdd1&gt;
                &lt;path&gt;/home/clickhouse/hdd1/&lt;/path&gt;
            &lt;/hdd1&gt;
        &lt;/disks&gt;
        &lt;policies&gt;
            &lt;moving_from_ssd_to_hdd&gt;
                &lt;volumes&gt;
                    &lt;hot&gt;
                        &lt;disk&gt;fast_ssd&lt;/disk&gt;
                        &lt;max_data_part_size_bytes&gt;1073741824&lt;/max_data_part_size_bytes&gt;
                    &lt;/hot&gt;
                    &lt;cold&gt;
                        &lt;disk&gt;hdd1&lt;/disk&gt;
                    &lt;/cold&gt;
                &lt;/volumes&gt;
                &lt;move_factor&gt;0.2&lt;/move_factor&gt;
            &lt;/moving_from_ssd_to_hdd&gt;
        &lt;/policies&gt;
    &lt;/storage_configuration&gt;
&lt;/yandex&gt;

</code></pre>
<h2 id="4-建表">4. 建表</h2>
<p>举个例子(实际使用必须确定清楚<strong>表引擎</strong>和<strong>聚合函数</strong>)，这里只是现场想个例子展示预聚合用法:</p>
<ul>
<li>表引擎使用: <code>MergeTree</code>，简单聚合函数</li>
<li>order by就是主键了</li>
<li>按时间分区</li>
<li>存储策略是优先SSD，上面那个</li>
<li>存储时间两个月</li>
</ul>
<pre><code class="language-sql">create table test.user_info
(
    record_time DateTime('Asia/Shanghai'),
    user String,
    cost Float64
)ENGINE = MergeTree()
ORDER BY (record_time,user)
PARTITION BY record_time
SETTINGS storage_policy = 'moving_from_ssd_to_hdd'
TTL record_time + INTERVAL 2 MONTH

-- 创建物化视图，比如每天每个用户cost总量
CREATE MATERIALIZED VIEW user_info_daily_mv
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(day)
SETTINGS storage_policy = 'moving_from_ssd_to_hdd'
ORDER BY (day,user)
AS SELECT
    toStartOfDay(record_time) AS day,
    user ,
    sum(cost) as cost_count
FROM test.user_info
GROUP BY (day,user)
</code></pre>
<h1 id="集群版带副本">集群版（带副本）</h1>
<h2 id="1-zookeeper集群部署">1. zookeeper集群部署</h2>
<blockquote>
<p>正式环境貌似要设置zookeeper的日志清理</p>
</blockquote>
<h3 id="测试用compose直接起">测试用compose直接起</h3>
<pre><code>version: '3.1'

services:
  zoo1:
    image: zookeeper
    restart: always
    hostname: zoo1
    ports:
      - 2181:2181
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=0.0.0.0:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=zoo3:2888:3888;2181

  zoo2:
    image: zookeeper
    restart: always
    hostname: zoo2
    ports:
      - 2182:2181
    environment:
      ZOO_MY_ID: 2
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=0.0.0.0:2888:3888;2181 server.3=zoo3:2888:3888;2181

  zoo3:
    image: zookeeper
    restart: always
    hostname: zoo3
    ports:
      - 2183:2181
    environment:
      ZOO_MY_ID: 3
      ZOO_SERVERS: server.1=zoo1:2888:3888;2181 server.2=zoo2:2888:3888;2181 server.3=0.0.0.0:2888:3888;2181
</code></pre>
<h3 id="手动安装">手动安装</h3>
<p>这部分删了，手动装挺麻烦的，这部分不大确定，虽然是能跑起来</p>
<h2 id="2-安装clickhouse">2. 安装clickhouse</h2>
<p>同上</p>
<h2 id="3-更新配置2分片2副本">3. 更新配置(2分片2副本)</h2>
<blockquote>
<p>不建议一个clickhouse-server拥有两个replicas来自不同shard。（除了性能问题，还会存在分布式DDL无法使用）<br>
见<a href="https://altinity.com/blog/2018/5/10/circular-replication-cluster-topology-in-clickhouse">CIRCULAR REPLICATION CLUSTER TOPOLOGY IN CLICKHOUSE</a>中的设计和<a href="https://github.com/ClickHouse/ClickHouse/issues/7611">github上issue所提的问题</a></p>
</blockquote>
<p>即每台机器是代表某个分片的某个副本</p>
<h3 id="所有配置文件">所有配置文件</h3>
<ul>
<li>config.xml (主配置文件)</li>
<li>users.xml (用户及配置限制)</li>
<li>storeage.xml (存储与策略配置)</li>
<li>metrika.xml（集群配置）</li>
</ul>
<h3 id="configxml-主配置文件">config.xml (主配置文件)</h3>
<pre><code>&lt;listen_host&gt;0.0.0.0&lt;/listen_host&gt;
</code></pre>
<h3 id="storagexml-存储与策略配置">storage.xml (存储与策略配置)</h3>
<p>见单机版，冷热数据划分，实际规则</p>
<ul>
<li>part超过1G的迁移</li>
<li>ssd快不够容量时迁移</li>
</ul>
<h3 id="userxml用户配置">user.xml(用户配置）</h3>
<ul>
<li>配置文件见<a href="https://clickhouse.tech/docs/en/operations/settings/settings-users/">user settings</a></li>
<li>可以设置个默认密码，用户账号管理用<a href="https://clickhouse.tech/docs/en/operations/access-rights/#access-control">SQL-driven workflow</a></li>
</ul>
<h3 id="metrikaxml文件cluster配置">metrika.xml文件（cluster配置）</h3>
<ul>
<li>申请4台机器，两个分片，2个副本</li>
<li>1和2的机器在同一个分片下，3和4在同一个分片下</li>
</ul>
<pre><code class="language-xml">&lt;yandex&gt;
    &lt;remote_servers&gt;
        &lt;test_cluster&gt;
            &lt;shard&gt;
                &lt;!-- &lt;secret&gt;&lt;/secret&gt; --&gt;
                &lt;!-- Optional. Shard weight when writing data. Default: 1. --&gt;
                &lt;weight&gt;1&lt;/weight&gt;
                &lt;!-- Optional. Whether to write data to just one of the replicas. Default: false (write data to all replicas). --&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt;
                    &lt;!-- Optional. Priority of the replica for load balancing (see also load_balancing setting). Default: 1 (less value has more priority). --&gt;
                    &lt;!-- &lt;priority&gt;1&lt;/priority&gt; --&gt;
                    &lt;host&gt;xx.xxx.xx.xx1&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;replica&gt;
                    &lt;host&gt;xx.xxx.xx.xx2&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
            &lt;shard&gt;
                &lt;weight&gt;1&lt;/weight&gt;
                &lt;internal_replication&gt;true&lt;/internal_replication&gt;
                &lt;replica&gt;
                    &lt;host&gt;xx.xxx.xx.xx3&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
                &lt;replica&gt;
                    &lt;host&gt;xx.xxx.xx.xx4&lt;/host&gt;
                    &lt;port&gt;9000&lt;/port&gt;
                &lt;/replica&gt;
            &lt;/shard&gt;
        &lt;/test_cluster&gt;
    &lt;/remote_servers&gt;

    &lt;!-- 这里其实就是标记当前机器属于哪个shard，以及副本代号 --&gt;
    &lt;macros&gt;
        &lt;shard&gt;01&lt;/shard&gt;
        &lt;replica&gt;xx.xxx.xx.xx1&lt;replica&gt;
    &lt;/macros&gt;

    &lt;!-- ZK--&gt;
    &lt;zookeeper&gt;
        &lt;node index=&quot;1&quot;&gt;
            &lt;host&gt;xx.xxx.xx.xx1&lt;/host&gt;
            &lt;port&gt;2181&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;2&quot;&gt;
            &lt;host&gt;xx.xxx.xx.xx2&lt;/host&gt;
            &lt;port&gt;2182&lt;/port&gt;
        &lt;/node&gt;
        &lt;node index=&quot;3&quot;&gt;
            &lt;host&gt;xx.xxx.xx.xx3&lt;/host&gt;
            &lt;port&gt;2183&lt;/port&gt;
        &lt;/node&gt;
    &lt;/zookeeper&gt;
    
&lt;/yandex&gt;
</code></pre>
<h3 id="宏定义统一建表语句">宏定义(统一建表语句)</h3>
<p>这里不设置layer层了，没必要</p>
<h4 id="记得每个节点都必须更新这个"><strong>记得每个节点都必须更新这个！！！</strong></h4>
<h4 id="注意同一个shard的节点的shard配置必须一致"><strong>注意同一个shard的节点的shard配置必须一致！！</strong></h4>
<pre><code class="language-xml">&lt;macros&gt;
    &lt;shard&gt;01&lt;/shard&gt;
    &lt;replica&gt;hostname&lt;/replica&gt;
&lt;/macros&gt;
</code></pre>
<h3 id="最终配置文件">最终配置文件</h3>
<h4 id="丢到configd目录下覆盖默认配置">丢到config.d目录下覆盖默认配置</h4>
<ul>
<li>xxx.xml（合并了listen配置和storeage配置）</li>
<li>metrika.xml（单独，这部分是热更新，无需重启）</li>
</ul>
<h4 id="用户配置丢到userd目录下覆盖默认配置">用户配置丢到user.d目录下覆盖默认配置</h4>
<ul>
<li>users.xml</li>
</ul>
<h3 id="集群样例">集群样例</h3>
<p>具体可以去查看system的cluster表，看看集群配置是否生效了</p>
<h2 id="4-每个节点启动click-server确定互通">4. 每个节点启动click server(确定互通)</h2>
<ul>
<li>9000端口用于clickhouse互通与clickhouse-client</li>
<li>8123端口为http访问</li>
</ul>
<h2 id="5-建表">5. 建表</h2>
<pre><code class="language-sql">/*分布式DDL建库*/
CREATE DATABASE test ON CLUSTER 'test_cluster'

/*分布式DDL建库，树引擎其实可以不写，就是默认值来的*/
CREATE TABLE test.test_info_local ON CLUSTER 'test_cluster'(
    ......
)ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/test/test_info_local','{replica}')
PARTITION BY record_time
ORDER BY (record_time)
TTL record_time + INTERVAL 6 MONTH
SETTINGS storage_policy = 'moving_from_ssd_to_hdd'

/*分布式DDL建立原始数据分布表*/
CREATE TABLE  test.test_info_local on CLUSTER 'test_cluster'
as test.test_info
ENGINE = Distributed(test_cluster,test,test_info_local,rand())

/*以下不写了，基本看官方文档详细点*/
/*物化视图有实际table的，只不过默认隐藏，我们也可以手动创建*/


/*分布式DDL创建物化视图*/
/*这里因为提前建好复制表了，不需要再设置engine那些*/



/**分布式DDL 创建全局视图*/

</code></pre>
<ul>
<li>分布式DDL跑一次就够了</li>
</ul>
<h2 id="6-实际应用">6. 实际应用</h2>
<h3 id="写本地表">写本地表</h3>
<p>最好直接写本地表，因为直接写分布式表，在clickhouse上还要再同步一次，实际上相当于双写了</p>
<h3 id="读分布式表">读分布式表</h3>
<h2 id="7-测试">7. 测试</h2>
<p>性能方面简单的可以看<a href="https://clickhouse.tech/docs/en/introduction/performance/">官方说明</a>，尽量批量写，这里其实还会涉及到clickhouse里part的概念，不细说了</p>
<blockquote>
<p>We recommend inserting data in packets of at least 1000 rows, or no more than a single request per second.</p>
</blockquote>
<h2 id="8-个人经验">8. 个人经验</h2>
<ul>
<li>表引擎要留意清楚，个人一般使用最多的是<code>SummingMergeTree</code>或者<code>AggregatingMergeTree</code>，分布式就加个<code>replica</code>前缀</li>
<li>clickhouse允许相同主键的数据存在，是否去重以及去重的规则具体看表引擎决定。</li>
<li>clickhouse不保证part merge的时机，这个是坑，某些实际应用场景时就会感受到的</li>
<li>可以对视图再进行视图的聚合，不过要注意，本质上是insert事件触发了视图，视图并不知道原表的数据</li>
<li>分布式用到zookeeper（这玩意还是没那么好用），这里依赖它主要是在分布式DDL执行和ReplicaMergeTree主备状态同步上（对于每个insert的数据part，clickhouse都会通过几个事务将记录添加到zookeeper上）</li>
</ul>
<p>有问题欢迎留言~</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gridea扩展(一)- 代码高亮]]></title>
        <id>https://geraltxli.github.io/post/gridea-kuo-zhan/</id>
        <link href="https://geraltxli.github.io/post/gridea-kuo-zhan/">
        </link>
        <updated>2021-05-30T14:27:40.000Z</updated>
        <summary type="html"><![CDATA[<blockquote>
<p>没想到Gridea默认没有代码高亮，那只能自己来了，使用<strong>highlightjs</strong>，修改一下主题里代码，   引入一下就好了。</p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<blockquote>
<p>没想到Gridea默认没有代码高亮，那只能自己来了，使用<strong>highlightjs</strong>，修改一下主题里代码，   引入一下就好了。</p>
</blockquote>
<!-- more -->
<h2 id="代码高亮">代码高亮</h2>
<ol>
<li>下载<a href="https://highlightjs.org/">highlight.js</a>，点<code>Get Version</code>去下载进行，里面也不少各种语言等之类的选择，一般默认就够用了</li>
</ol>
<figure data-type="image" tabindex="1"><img src="https://geraltxli.github.io/post-images/1622428479016.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>
<p>下载完后解压，简单点就把整个文件夹<code>highlight</code>都丢到gridea数据目录的<code>static</code>目录下（不过其实也可以直接copy里面的<code>highlight.pack.js</code>和<code>styles</code>目录）</p>
</li>
<li>
<p>去<code>themes</code>目录下修改，一般只有文章会用到，所以直接修改<code>post.ejs</code>。在head里加几行代码就行了，这里我选了<code>github-dark</code>样式，这个看自己爱好</p>
</li>
</ol>
<pre><code class="language-html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;&lt;%= themeConfig.domain %&gt;/highlight/styles/github-dark.css&quot;&gt;
    &lt;script src=&quot;&lt;%= themeConfig.domain %&gt;/highlight/highlight.pack.js&quot;&gt;&lt;/script&gt;
    &lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Golang-AES加密（CBC模式，PKCS7填充）]]></title>
        <id>https://geraltxli.github.io/post/golang-aes-jia-mi-cbc-mo-shi-pkcs7-tian-chong/</id>
        <link href="https://geraltxli.github.io/post/golang-aes-jia-mi-cbc-mo-shi-pkcs7-tian-chong/">
        </link>
        <updated>2021-05-30T13:33:56.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://github.com/FakerGit/go-tools/tree/master/encrypt">代码地址</a></p>
<blockquote>
<p>对称加密算法，即加密和解密使用一样的密钥的加解密算法。<br>
分组密码（block cipher），是每次只能处理特定长度的一块（block）数据的一类加解密算法。<br>
目前常见的对称加密算法DES、3DES、AES都是属于分组密码。</p>
</blockquote>
]]></summary>
        <content type="html"><![CDATA[<p><a href="https://github.com/FakerGit/go-tools/tree/master/encrypt">代码地址</a></p>
<blockquote>
<p>对称加密算法，即加密和解密使用一样的密钥的加解密算法。<br>
分组密码（block cipher），是每次只能处理特定长度的一块（block）数据的一类加解密算法。<br>
目前常见的对称加密算法DES、3DES、AES都是属于分组密码。</p>
</blockquote>
<!-- more -->
<h3 id="背景">背景</h3>
<p>Golang没有像PHP那样提供一个现成的aes加密函数，不过标准库里有crypto，利用里面的aes等可以自己封装个加密函数，不过需要理解下整个加解密的过程和原理</p>
<!-- more -->
<hr>
<h3 id="aes加密详解">AES加密详解</h3>
<h4 id="1-参考文章golang-中aes加密详解">1. 参考文章<a href="https://blog.csdn.net/xiaohu50/article/details/51682849">golang 中AES加密详解</a></h4>
<h4 id="2-这里使用的是aes加密中的cbc模式块加密需要划分成整数长度相等个消息块不断加密串行分组长度是固定128位但密钥的长度可以使用128位192位或者256位这里指的是bit即密钥162432长度对应aes-128-aes-192-aes-256">2. 这里使用的是AES加密中的CBC模式，块加密需要划分成整数长度相等个消息块不断加密（串行），分组长度是固定128位，但密钥的长度可以使用128位，192位或者256位（这里指的是bit），即密钥16，24，32长度对应AES-128, AES-192, AES-256。</h4>
<h4 id="3初始向量要求随机但不需要保密">3.初始向量要求随机，但不需要保密。</h4>
<hr>
<h3 id="代码">代码</h3>
<p>自己研究代码比较清晰，根据<a href="https://golang.org/src/crypto/cipher/example_test.go">golang标准库AES实例代码</a>，再参考网上的PKCS7填充，最后进行base64的编码（因为加密后有些字符不可见）。最后Encrypt和Dncrypt两个就是AES加解密（CBC模式，PKCS7填充）封装后的函数，密钥位数限定16,24,32（要注意的是密钥无论多少，blocksize都是固定16）</p>
<pre><code class="language-go">package encrypt

import (
   &quot;bytes&quot;
   &quot;crypto/aes&quot;
   &quot;io&quot;
   &quot;crypto/rand&quot;
   &quot;crypto/cipher&quot;
   &quot;encoding/base64&quot;
)

/*CBC加密 按照golang标准库的例子代码
不过里面没有填充的部分,所以补上
*/

//使用PKCS7进行填充，IOS也是7
func PKCS7Padding(ciphertext []byte, blockSize int) []byte {
   padding := blockSize - len(ciphertext) % blockSize
   padtext := bytes.Repeat([]byte{byte(padding)}, padding)
   return append(ciphertext, padtext...)
}

func PKCS7UnPadding(origData []byte) []byte {
   length := len(origData)
   unpadding := int(origData[length-1])
   return origData[:(length - unpadding)]
}

//aes加密，填充秘钥key的16位，24,32分别对应AES-128, AES-192, or AES-256.
func AesCBCEncrypt(rawData,key []byte) ([]byte, error) {
   block, err := aes.NewCipher(key)
   if err != nil {
   	panic(err)
   }

   //填充原文
   blockSize := block.BlockSize()
   rawData = PKCS7Padding(rawData, blockSize)
   //初始向量IV必须是唯一，但不需要保密
   cipherText := make([]byte,blockSize+len(rawData))
   //block大小 16
   iv := cipherText[:blockSize]
   if _, err := io.ReadFull(rand.Reader,iv); err != nil {
   	panic(err)
   }

   //block大小和初始向量大小一定要一致
   mode := cipher.NewCBCEncrypter(block,iv)
   mode.CryptBlocks(cipherText[blockSize:],rawData)

   return cipherText, nil
}

func AesCBCDncrypt(encryptData, key []byte) ([]byte,error) {
   block, err := aes.NewCipher(key)
   if err != nil {
   	panic(err)
   }

   blockSize := block.BlockSize()

   if len(encryptData) &lt; blockSize {
   	panic(&quot;ciphertext too short&quot;)
   }
   iv := encryptData[:blockSize]
   encryptData = encryptData[blockSize:]

   // CBC mode always works in whole blocks.
   if len(encryptData)%blockSize != 0 {
   	panic(&quot;ciphertext is not a multiple of the block size&quot;)
   }

   mode := cipher.NewCBCDecrypter(block, iv)

   // CryptBlocks can work in-place if the two arguments are the same.
   mode.CryptBlocks(encryptData, encryptData)
   //解填充
   encryptData = PKCS7UnPadding(encryptData)
   return encryptData,nil
}


func Encrypt(rawData,key []byte) (string,error) {
   data, err:= AesCBCEncrypt(rawData,key)
   if err != nil {
   	return &quot;&quot;,err
   }
   return base64.StdEncoding.EncodeToString(data),nil
}

func Dncrypt(rawData string,key []byte) (string,error) {
   data,err := base64.StdEncoding.DecodeString(rawData)
   if err != nil {
   	return &quot;&quot;,err
   }
   dnData,err := AesCBCDncrypt(data,key)
   if err != nil {
   	return &quot;&quot;,err
   }
   return string(dnData),nil
}
</code></pre>
<pre><code class="language-json">{
    &quot;json&quot;:&quot;123&quot;,
    &quot;hah&quot;:&quot;123&quot;
}
</code></pre>
<hr>
<p><a href="https://github.com/FakerGit/go-tools">github代码地址</a></p>
<hr>
<p>参考：</p>
<ol>
<li><a href="https://blog.csdn.net/xiaohu50/article/details/51682849">golang 中AES加密详解</a></li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一次完整的网络请求过程]]></title>
        <id>https://geraltxli.github.io/post/yi-ci-wan-zheng-de-wang-luo-qing-qiu-guo-cheng/</id>
        <link href="https://geraltxli.github.io/post/yi-ci-wan-zheng-de-wang-luo-qing-qiu-guo-cheng/">
        </link>
        <updated>2021-05-30T07:03:38.000Z</updated>
        <summary type="html"><![CDATA[<p>从浏览器访问某个网站时所发生的事情</p>
]]></summary>
        <content type="html"><![CDATA[<p>从浏览器访问某个网站时所发生的事情</p>
<!-- more -->
<!-- more -->
<h2 id="一-dns解析">一、 DNS解析</h2>
<ul>
<li>浏览器搜索自身缓存的DNS记录（所以才会有修改host后有时候没立刻生效的原因）</li>
<li>搜索系统的hosts文件</li>
<li>路由器也有DNS缓存</li>
<li>无则继续向ISP的DNS服务请求</li>
<li>无
<ul>
<li>非转发模式：则向根服务器请求，进行递归查询，即根DNS服务器返回定义域名服务器的IP，然后到顶级域名（如<code>.com</code>服务器查询）解析，如果无法解析就会继续提供此下一级dns服务器（如<code>qq.com</code>去解析），直到找到位置</li>
<li>转发模式：dns服务器自身请求转发给上一级</li>
</ul>
</li>
</ul>
<blockquote>
<p>从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。</p>
</blockquote>
<h2 id="二-tcpip-协议栈通信过程">二、TCP/IP 协议栈通信过程</h2>
<figure data-type="image" tabindex="1"><img src="https://geraltxli.github.io/post-images/1622358377997.png" alt="" loading="lazy"></figure>
<h3 id="1-应用层">1. 应用层</h3>
<p>定义数据格式，并按照格式解析数据。<br>
此时是HTTP协议，header的content-type定义格式，body填数据</p>
<h3 id="2-传输层">2. 传输层</h3>
<h4 id="协议栈上">协议栈上</h4>
<p>添加了TCP首部，记录端口，确认主机上应用程序的身份，把数据包交给对应的应用程序</p>
<h4 id="tcp三次握手和四次挥手">TCP三次握手和四次挥手</h4>
<figure data-type="image" tabindex="2"><img src="https://geraltxli.github.io/post-images/1622358358701.png" alt="" loading="lazy"></figure>
<blockquote>
<p>ESTABLISHED <code>əˈstabliSHt</code> 已建立成功的状态</p>
</blockquote>
<ul>
<li>为什么握手要三次？为了防止已经失效的连接请求报文段突然又传到服务端</li>
<li>为什么挥手要四次？当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端</li>
<li>为什么TIME_WAIT状态需要经过2MSL（max segment lifetime，即最大报文段生存时间，一般1分钟到4分钟)才能返回到CLOSE状态？四个报文都发送完毕，我们可以直接进入CLOSE状态了，
<ul>
<li>但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。</li>
<li>保证此次连接的重复数据段从网络中消失<br>
TCP分节可能由于路由器异常而“迷路”，在“迷路”期间，TCP发送端可能因确认超时而重发这个分节，“迷路”的分节在路由器恢复正常后也会被发送到最终的目的地，这个迟到的“迷路”分节到达时可能会引起问题。在关闭“前一个连接”之后，马上又建立起一个相同的IP和端口之间的“新连接”，这会导致“前一个连接”的迷路重复分组在“前一个连接”终止后到达，从而被“新连接”接收到了。<br>
为了避免以上情况，TCP/IP协议不允许处于TIME_WAIT状态的连接启动一个新的可用连接，因为TIME_WAIT状态持续2MSL，这就可以保证当成功建立一个新TCP连接的时候，来自旧连接重复分组已经在网络中消失。</li>
</ul>
</li>
</ul>
<h3 id="3-网络层">3. 网络层</h3>
<p>定义网络地址，区分网段，子网内MAC寻址，对不同子网的数据包进行路由</p>
<ul>
<li>IP协议通过子网掩码计算网络地址，判断两个主机是否属于同一个子网</li>
<li>ARP协议以太网广播给子网的所有主机，IP地址相同的话，主机会返回MAC地址，不同则丢弃。与此同时，ARP会缓存这个映射关系。此时寻址限制于同一个子网</li>
<li>路由协议，不同子网，通过本子网的网关进行路由</li>
<li></li>
</ul>
<h3 id="4-链路层">4. 链路层</h3>
<ul>
<li>对电信号进行分组并形成具有特定意义的数据帧，然后以广播的形式通过物理介质发送给接收方。以太网规定一组电信号就是一个数据包，一个数据包被称为一帧， 制定这个规则的协议就是以太网协议。</li>
<li>子网广播，主机通过MAC地址来决定是否处理数据</li>
</ul>
]]></content>
    </entry>
</feed>